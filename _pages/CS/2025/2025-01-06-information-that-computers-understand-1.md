---
title: "💾 [CS] 1Day 1CS - 컴퓨터가 이해하는 정보(1)"
tags:
    - CS
date: "2025-01-06"
thumbnail: "/assets/img/thumbnail/cs.jpeg"
---

# 💾 [CS] 1Day 1CS - 컴퓨터가 이해하는 정보(1)
## 📌 Intro.
- ↘︎ 컴퓨터가 어떻게 문자와 숫자를 인식하는지, 그리고 그렇게 표현된 정적인 데이터가 명령어에 의해 어떻게 실행되는지 정리함.
- ↘︎ CPU는 기본적으로 0과 1만을 이해.
    - ↘︎ 여기서 0과 1을 나타내는 가장 작은 정보의 단위를 **비트(bit)라고** 함.
- ↘︎ 1비트 ➞ 0 또는 1, 2개($2^1$)의 정보를 표현할 수 있음
    - ↘︎ 2비트 ➞ 4개($2^2$)의 정보, 3비트 ➞ 8개($2^3$)의 정보를 표현할 수 있음
        - ↘︎ **즉, N비트는 ($2^N)$ 개의 정보를 표현할 수 있음.**

- ↘︎ 프로그램 크기를 말할 때는 바이트(byte), 킬로바이트(kB), 메가바이트(MB), 기가바이트(GB), 테라바이트(TB) 등을 사용.
    - ↘︎ **바이트(byte)는 여덟 비트를 묶은 단위를 말함.**
        - ↘︎ 하나의 바이트로 표현할 수 있는 정보는 $2^8 = 256$개
    - ↘︎ 킬로바이트, 메가바이트, 기가바이트, 테라바이트 단위는 모두 이전 단위 1,000개를 묶은 단위를 말함.

|구분|비트|
| -------- | -------- |
|1 byte|8 비트|
|1 kB|1,000 바이트|
|1 MB|1,000 킬로바이트|
|1 GB|1,000 메가바이트|
|1 TB|1,000 기가바이트|

- ↘︎ **CPU 관점에서의 정보 단위:**
    - ↘︎ **워드(Word) :** CPU가 한 번에 처리할 수 있는 데이터의 크기
- ↘︎ 프로그램의 크기가 2GB라고 해서 CPU도 한 번에 2GB를 읽어 들여 처리하는 것이 아니다.
    - ↘︎ **CPU는 프로그램을 워드(Word) 단위로 읽어 들이고 처리한다.**
        - ↘︎ 만약 CPU가 한 번에 16비트를 처리할 수 있다면 1워드(Word)는 16비트가 되거, 한 번에 32비트를 처리할 수 있다면 32비트가 되는 것이다.
            - ↘︎ 워드의 크기는 CPU마다 다르지만, 현대 컴퓨터 대부분의 워드 크기는 32비트, 혹은 64비트이다.

## ✅1️⃣ 데이터 - 0과 1로 숫자 표현하기.
- ↘︎ CPU는 컴퓨터 내부에서 **2진법(binary)을 사용해** 2 이상, 0 이하의 수를 이해함.
- ↘︎ 컴퓨터가 사용하는 2진법은 **숫자 1을 넘어가는 시점에 자리올림해 0과 1, 2개의 숫자만으로 모든 수를 표현함.**
- ↘︎ 2진수로 표현된 수는 숫자 뒤에 아래첨자로 (2)를 붙이거나 2진수 앞에 0b를 붙임.

<img src = "https://github.com/devKobe24/images2/blob/main/CS_IMG/cs_binary.png?raw=true">

- ↘︎ 컴퓨터 내부에서 2진수로 **소수를 나타내는 방법:**
    - ↘︎ 컴퓨터의 소수 표현을 학습시 가장 중요한 핵심은 **표현하고자 하는 소수와 실제로 저장된 소수 간에 오차가 존재할 수 있다는 점이다.**
        - ↘︎ 예시:
        ```python
        a = 0.1
        b = 0.2
        c = 0.3
        
        if a + b == c:
            print("Equal")
        else:
            print("Not Equal")
        ```
    - ↘︎ 결과: 'Not Equal'
        - ↘︎ 이러한 오차는 비단 파이썬에서만 발생하는 것이 아니고, C/C++, Java, JS 등 많은 프로그래밍 언어에서 'Not Equal'이 결과로 출력된다.
            - ↘︎ 이러한 오차의 존재, 그 발생 원인을 알지 못한다면 코딩 테스트나 정밀도 높은 개발 업무에 제대로 대처할 수 없다.
- ↘︎ 이러한 오차가 발생하는 이유:
    - ↘︎ 컴퓨터 내부에서는 소수점을 나타내기 위해 대표적으로 **부동 소수점(floating point)** 표현 방식을 이용함.
        - ↘︎ 이 방식의 정밀도에 한계가 있기 때문임.
- ↘︎ **부동 소수점(floating point) :**
    - ↘︎ 소수점이 고정되어 있지 않은 소수 표현 방식으로, 필요에 따라 소수점의 위치가 이동할 수 있고 유동적(floating)이라는 의미.
    - ↘︎ 예시:
        - ↘︎ 10진수 123.123이라는 수를 **$m × 10^n$의 꼴로 나타내면 $1.23123 × 10^2$으로 표현할 수도 있고, $1231.23 × 10^{-1}$으로 표현 가능.**
            - ↘︎ 여기에서 제곱으로 표현된 2와 -1을 **지수(exponent)**, 1.23123과 1231.23을 **가수(significand)라고** 함.
- ↘︎ 2진수 체계에서의 소수 표현:
    - ↘︎ **$m × 2^n$의 꼴로 나타냄.**
        - ↘︎ 가령 107.6640625라는 10진수 소수가 있다고 가정.
            - ↘︎ 이를 2진수로 나타내면 $1101011.1010101$이다.
            - ↘︎ 이 2진수 소수는 $1.1010111010101 × 2^6$으로 표현할 수도 있고, $110101110.10101 × 2^{-2}$으로 표현할 수 있음.
                - ↘︎ 이 경우에 지수는 각각 $6$, $-2$이고, 가수는 $1.1010111010101$, $110101110.10101$이다.
                    - ↘︎ 2의 지수가 양수일 때는 **$2^{소수점을\ 왼쪽으로\ 이동한\ 횟수}$**, 2의 지수가 음수일 때는 **$2^{소수점을\ 오른쪽으로\ 이동한\ 횟수}$** 라고 생각해도 됨.
- ↘︎ 오늘날 대부분의 컴퓨터는 2진수의 지수와 가수를 다음과 같은 형식으로 저장함.
    - ↘︎ 이와 같은 부동 소수점 저장 방식을 **IEEE 754**라고 함

<img src = "https://github.com/devKobe24/images2/blob/main/CS_IMG/cs-IEEE_754.png?raw=true">

- ↘︎ 그림과 같은 형태로 소수가 저장된다고 할 때, 가수의 정수부에는 1로 통일된 **정규화한 수(normalized number)가** 저장됨.
    - ↘︎ 즉, 가수는 $1.OOO...$의 형태를 띄고 있다.
    - ↘︎ 앞서 예로 들었던 2진수 $1101011.1010101$의 경우 $110101110.10101 × 2^{-2}$이 아닌 $1.1010111010101 × 2^6$으로 저장되는 셈이다.
    - ↘︎ 그럼 $2^{지수} × 1.OOO...$의 형태의 소수를 저장할 때는 **지수**에 해당하는 값과 $OOO...$에 해당하는 **소수 부분(fraction)** 만을 저장하면 된다.
        - ↘︎ 어차피 $2^{지수}$의 2와 $1.OOO...$은 1은 통일되어 있는 값이기 때문이다.
            - ↘︎ 따라서 컴퓨터가 가수를 저장할 때는 (가수인 $1.OOO...$에서 1을 제외한) OOO에 해당하는 소수 부분만 저장하게 된다.
                - ↘︎ 가령 $1.1010111010101 × 2^6$의 가수를 저장할 때는 $1010111010101$이 저장되는 것이다.

<img src = "https://github.com/devKobe24/images2/blob/main/CS_IMG/cs-significand.png?raw=true">

- ↘︎ 컴퓨터가 지수를 저장할 때는 **바이어스(bias)** 값이 더해져서 저장되며, 이때 바이어스 값은 $2^{k-1}-1$(k는 지수의 비트 수)이다.
    - ↘︎ 지수를 표현하기 위해 8비트가 사용되었다면 바이어스 값은 $2^7-1$인 127이고, 11비트가 사용되었다면 바이어스 값은 $2^{10}-1$인 1,023이다
        - ↘︎ 즉, $1.1010111010101 × 2^6$이 32비트로 저장될 때는 127+6인 133(2진수 10000101)으로 저장되는 셈이다.
        <img src = "https://github.com/devKobe24/images2/blob/main/CS_IMG/cs-significand-2.png?raw=true">
- ↘︎ 결과적으로 $1101011.1010101$(10진수 107.6640625)라는 수는 다음과 같이 저장됩니다.
<img src = "https://github.com/devKobe24/images2/blob/main/CS_IMG/cs-significand-3.png?raw=true">
- ↘︎ **10진수 소수를 2진수로 표현할 때, 10진수 소수와 2진수 소수의 표현이 딱 맞아떨어지지 않을 수 있다는 점을 유의해야 한다.**
- ↘︎ 컴퓨터의 저장공간은 한정적이기 때문에 무한히 많은 소수점을 저장할 수는 없다.
    - ↘︎ 그래서 딱 맞아떨어지지 않는 소수를 표현할 때는 일부 소수점을 생략하여 저장한다.
        - ↘︎ 그래서 오차가 발생하는 것이다.

### ✅🙋‍♂️ 여기서 잠깐!
#### 📌 16진법
- ↘︎ 2진법에는 단점이 있음.
    - ↘︎ 표현하는 **숫자의 길이가 너무 길어진다는 점.**
    - ↘︎ 가령 10진수 '128'을 2진수로 표현하면 '100000000₍₂₎' 여덟 자리의 숫자가 필요함.
        - ↘︎ 그래서 컴퓨터가 이해하는 정보를 표현시 16진수도 함께 사용함.
- ↘︎ 16진수를 나타내는 **16진법(hexadecimal)은 숫자 15를 넘어가는 시점에 자리올림을 하는 숫자 표현 방식임.**
- ↘︎ 16진법 체계에서는 10진수 10, 11, 12, 13, 14, 15를 각각 **A, B, C, D, E, F**로 표기함

|10진수|0|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|...|
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---- | --- | --- | --- |
|16진수|0|1|2|3|4|5|6|7|8|9|A|B|C|D|E|F|10|11|...|

- ↘︎ 16진수로 표현된 수는 뒤에 아래첨자로 (16)을 붙이거나 16진수 앞에 0x를 붙임.
- ↘︎ 16진수의 활용:
    - ↘︎ 소스 코드에 16진수를 직접 쓰기도 함.
    - ↘︎ MAC 주소
    - ↘︎ IPv6 주소 표현
