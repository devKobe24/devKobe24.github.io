i---
title: "💾 [CS] 캐시 메모리"
tags:
    - CS
date: "2024-05-09"
thumbnail: "/assets/img/thumbnail/cs.jpeg"
---

# 캐시 메모리

## 1. 저장 장치 계층 구조.
저장 장치는 일반적으로 아래와 같은 명제를 따릅니다.
- 1. CPU와 가까운 저장 장치는 빠르고, 멀리 있는 저장 장치는 느리다.
- 2. 속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다.

<img src = "https://github.com/devKobe24/images/blob/main/%E1%84%8C%E1%85%A5%E1%84%8C%E1%85%A1%E1%86%BC%E1%84%8C%E1%85%A1%E1%86%BC%E1%84%8E%E1%85%B5%E1%84%80%E1%85%A8%E1%84%8E%E1%85%B3%E1%86%BC%E1%84%80%E1%85%AE%E1%84%8C%E1%85%A9%E1%84%80%E1%85%B3%E1%84%85%E1%85%B5%E1%86%B7.png?raw=true">

컴퓨터가 사용하는 저장 장치들은 'CPU에 얼마나 가까운가'를 기준으로 계층적으로 나타낼 수 있습니다.
- 이를 **"저장 장치 계층 구조(memory hierachy)"** 라고 합니다.

CPU에 가까운 저장 장치일수록 빠르고, 용량이 작고, 비쌉니다.
- 위 계층으로 올라갈수록 CPU와 가깝고 용량은 작지만 빠른 저장 장치입니다.
- 아래 계층으로 내려갈수록 CPU와 멀고 용량은 크지만 느린 저장 장치입니다.
- 가격 또한 일반적으로 위 계틍으로 올라갈수록 비싸고, 아래 계층으로 내려갈수록 저렴합니다.

---

## 2. 캐시 메모리.

**캐시 메모리(cache memory)** 는 CPU와 메모리 사이에 위치하고, 레지스터보다 용량이 크고 메모리보다 빠른 SRAM 기반의 저장 장치입니다.

캐시 메모리는 CPU의 연산 속도와 메모리 접근 속도의 차이를 조금이나마 줄이기 위해 탄생했습니다.
- CPU가 매번 메모리에 왔다 갔다 하는 건 시간이 오래 걸리니, 메모리에서 CPU가 사용할 일부 데이터를 미리 캐시 메모리로 가지고 와서 활용하자는 것입니다.

<img src = "https://github.com/devKobe24/images/blob/main/%E1%84%8F%E1%85%A2%E1%84%89%E1%85%B5%E1%84%86%E1%85%A6%E1%84%86%E1%85%A9%E1%84%85%E1%85%B5%E1%84%89%E1%85%A1%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%8B%E1%85%B2%E1%84%86%E1%85%AE%E1%84%80%E1%85%B3%E1%84%85%E1%85%B5%E1%86%B7.png?raw=true">

캐시 메모리까지 반영한 저장 장치 계층 구조는 아래와 같이 그릴 수 있습니다.

<img src = "https://github.com/devKobe24/images/blob/main/%E1%84%8F%E1%85%A2%E1%84%89%E1%85%B5%E1%84%86%E1%85%A6%E1%84%86%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%A5%E1%84%8C%E1%85%A1%E1%86%BC%E1%84%8C%E1%85%A1%E1%86%BC%E1%84%8E%E1%85%B5%E1%84%80%E1%85%A8%E1%84%8E%E1%85%B3%E1%86%BC%E1%84%80%E1%85%AE%E1%84%8C%E1%85%A9%E1%84%80%E1%85%B3%E1%84%85%E1%85%B5%E1%86%B7.png?raw=true">

컴퓨터 내부에는 여러 개의 캐시 메모리가 있습니다.
그리고 이 캐시 메모리들은 CPU(코어)와 가까운 순서대로 계층을 구성합니다.

코어와 가장 가까운 캐시 메모리를 **L1(level 1) 캐시.**, 그다음 가까운 캐시 메모리를 **L2(level 2) 캐시**, 그다음 가까운 캐시 메모리를 **L3(level 3) 캐시** 라고 부릅니다.

<img src = "https://github.com/devKobe24/images/blob/main/L1,2,3%E1%84%8F%E1%85%A2%E1%84%89%E1%85%B5.png?raw=true">

> note : 일반적으로 L1 캐시와 L2 캐시는 코어 내부에, L3 캐시는 코어 외부에 위치해 있습니다.

저장 장치 계층 구조를 이해했다면 짐작할 수 있다시피 캐시 메모리 용량은 L1, L2, L3 순으로 커지고, 속도는 L3, L2, L1 순으로 빨라집니다.

가격은 일반적으로 L3, L2, L1 순으로 비싸집니다.

CPU가 메모리 내에 데이터가 필요하다고 판단하면 우선 L1 캐시에 해당 데이터가 있는지를 알아보고, 없다면 L2, L3 캐시 순으로 데이터를 검색합니다.

멀티 코어 프로세서 L1 - L2 - L3 캐시는 일반적으로 다음과 같이 구현됩니다.
- L1 캐시와 L2 캐시는 코어마카 고유한 캐시 메모리로 할당되고, L3 캐시는 여러 코어가 공유하는 형태로 사용됩니다.

<img src = "https://github.com/devKobe24/images/blob/main/%E1%84%86%E1%85%A5%E1%86%AF%E1%84%90%E1%85%B5%E1%84%8F%E1%85%A9%E1%84%8B%E1%85%A5%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%89%E1%85%A6%E1%84%89%E1%85%A5%E1%84%80%E1%85%B3%E1%84%85%E1%85%B5%E1%86%B7.png?raw=true">

> 여기서 잠깐!
> = 분리형 캐시 =
> 코어와 가장 가까운 L1 캐시는 조금이라도 접근 속도를 빠르게 만들기 위해 명령어만을 저장하는 L1 캐시인 L1 캐시와 데이터만을 저장하는 L1 캐시인 L1D 캐시로 분리하는 경우도 있습니다.
> 이를 **분리형 캐시(split cache)** 라고 합니다.

<img src = "https://github.com/devKobe24/images/blob/main/%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B5%E1%84%92%E1%85%A7%E1%86%BC%E1%84%8F%E1%85%A2%E1%84%89%E1%85%B5.png?raw=true">

아래는 저장 장치 계층 구조를 세부적으로 나타낸 그림입니다.

<img src = "https://github.com/devKobe24/images/blob/main/%E1%84%8C%E1%85%A5%E1%84%8C%E1%85%A1%E1%86%BC%E1%84%8C%E1%85%A1%E1%86%BC%E1%84%8E%E1%85%B5%E1%84%80%E1%85%A8%E1%84%8E%E1%85%B3%E1%86%BC%E1%84%80%E1%85%AE%E1%84%8C%E1%85%A9%E1%84%89%E1%85%A6%E1%84%87%E1%85%AE%E1%84%8C%E1%85%A5%E1%86%A8%E1%84%8B%E1%85%B3%E1%84%85%E1%85%A9%E1%84%82%E1%85%A1%E1%84%90%E1%85%A1%E1%84%82%E1%85%A2%E1%86%AB%E1%84%80%E1%85%B3%E1%84%85%E1%85%B5%E1%86%B7.png?raw=true">

---

## 3. 참조 지역성 원리.
- **캐시 히트(cache hit) :** 메모리는 실행 중인 대상을 저장한다면 캐시 메모리는 CPU가 사용할 법한 대상을 예측하여 저장합니다.
    - 이때 자주 사용될 것으로 예측한 데이터가 실제로 들어맞아 캐시 메모리 내 데이터가 CPU에서 활용되는 경우를 캐시 히트하고 합니다.

- **캐시 미스(cache miss) :** 자주 사용될 것으로 예측하여 캐시 메모리에 저장했지만, 예측이 틀려 메모리에서 필요한 데이터를 직접 가져와야 하는 경우를 캐시 미스라고합니다.
    - 캐시 미스가 발생하면 CPU가 필요한 데이터를 메모리에서 직접 가져와야 하기 떄문에 캐시 메모리의 이점을 활용할 수 없습니다.
        - 당연히 캐시 미스가 자주 발생하면 성능이 떨어지게 될 것 입니다.

- **캐시 적중률(cache hit ratio) :** 캐시가 히트되는 비율.
    - 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)

## 3.1 캐시 적중률을 높이는 방법.
캐시 메모리는 한 가지 원칙에 따라 메모리로부터 가져올 데이터를 결정합니다.
바로 **참조 지역성의 원리(locality of reference, principle of locality)** 입니다.

- **참조 지역성의 원리 :** CPU가 메모리에 접근할 때의 주된 경향을 바탕으로 만들어진 원리입니다.
    - 1. CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있다.
    - 2. CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있다.

## 3.1.1 '최근에 접근했던 메모리 공간에 다시 접근하려는 경향'은 무엇일까요?
- **시간 지역성(temporal locality) :** '최근에 접근했던 메모리 공간에 다시 접근하려는 경향'
    - 예를 들어 변수에 값을 저장하고 나면 언제든 변수에 다시 접근하여 변수에 저장된 값을 사용할 수 있습니다.
        - 이는 달리 말해 'CPU는 변수가 저장된 메모리 공간을 언제든 다시 참조할 수 있다'는 것을 의미합니다.
        - 그리고 변수에 저장된 값은 일반적으로 한 번만 사용되지 않고 프로그램이 실행되는 동안 여러 번 사용됩니다.
            - 즉, CPU는 최근 접근했던 (변수가 저장된) 메모리 공간을 여러 번 다시 접근할 수 있습니다.

### 3.1.2 '접근한 메모리 공간 근처를 접근하려는 경향'은 무엇일까요?
- **공간 지역성(spatial locality) :** '접근한 메모리 공간 근처를 접근하려는 경향'
    - CPU가 실행하려는 프로그램은 보통 관련 데이터들끼리 한데 모여 있습니다.
        - 가령 메모리 내에 워드 프로세서 프로그램, 웹 브라우저 프로그램, 게임 프로그램이 있다고 가정해 봅시다.
        - 이 세 프로그램은 서로 관련 있는 데이터끼리 모여서 저장됩니다.
            - 워드 프로세서 프로그램은 워드 프로세서 관련 데이터들이 모여 저장되고, 웹 브라우저 프로그램은 웹 브라우저 관련 데이터들이 모여 저장되고, 게임 프로그램은 게임 관련 데이터들이 모여 저장됩니다.
                - 그리고 하나의 프로그램 내에서도 관련있는 데이터들은 모여서 저장됩니다.
                    - 가령 워드 프로세서 프로그램에 자동 저장 기능, 입력 기능, 출력 기능이 있다고 했을 때 각각의 관련한 데이터는 모여 저장됩니다.

<img src = "https://github.com/devKobe24/images/blob/main/%E1%84%80%E1%85%A9%E1%86%BC%E1%84%80%E1%85%A1%E1%86%AB%E1%84%8C%E1%85%B5%E1%84%8B%E1%85%A7%E1%86%A8%E1%84%89%E1%85%A5%E1%86%BC%E1%84%80%E1%85%B3%E1%84%85%E1%85%B5%E1%86%B8.png?raw=true">

- CPU가 워드 프로세서 프로그램을 실행할 적에는 워드 프로세서 프로그램이 모여 있는 공간 근처를 집중적으로 접근할 것이고, 사용자가 입력을 할 적에는 입력 기능이 모여 있는 공간 근처를 집중적으로 접근할 것입니다.
    - 이렇게 '접근한 메모리 공간 근처를 접근하려는 경향'을 **공간 지역성** 이라고 합니다.

## 📝 정리.
캐시 메모리는 이렇듯 참조 지역성 원리에 입각해 CPU가 사용할 법한 데이터를 예측합니다.

## 키워드로 정리하는 핵심 포인트.

- **저장 장치 계층 구조**는 각기 다른 용량과 성능의 저장 장치들을 계층화하여 표현한 구조입니다.
- **캐시 메모리**는 CPU의 연산 속도와 메모리 접근 속도의 차이를 줄이기 위한 저장 장치입니다.
- **캐시 적중률**이 높으면 CPU의 메모리 접근 횟수를 줄일 수 있습니다.
- 캐시 메모리는 **참조 지역성의 원리**에 따라 데이터를 예측하여 캐시 적중률을 높입니다.
